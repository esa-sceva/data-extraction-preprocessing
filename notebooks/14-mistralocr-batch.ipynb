{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mistralai import Mistral\n",
    "import base64\n",
    "import os\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import time\n",
    "from IPython.display import clear_output\n",
    "\n",
    "api_key = \"xxx\"\n",
    "client = Mistral(api_key=api_key)\n",
    "ocr_model = \"mistral-ocr-latest\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "\n",
    "# def encode_image_data(image_data):\n",
    "#     try:\n",
    "#         # Ensure image_data is bytes\n",
    "#         if isinstance(image_data, bytes):\n",
    "#             # Directly encode bytes to base64\n",
    "#             return base64.b64encode(image_data).decode('utf-8')\n",
    "#         else:\n",
    "#             # Convert image data to bytes if it's not already\n",
    "#             buffered = BytesIO()\n",
    "#             image_data.save(buffered, format=\"JPEG\")\n",
    "#             return base64.b64encode(buffered.getvalue()).decode('utf-8')\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error encoding image: {e}\")\n",
    "#         return None\n",
    "\n",
    "def encode_image_data(image_path):\n",
    "    \"\"\"Encode a local image to base64 with proper MIME type.\"\"\"\n",
    "    try:\n",
    "        file_extension = os.path.splitext(image_path)[1].lower()\n",
    "        mime_type = \"image/jpeg\"  # Default\n",
    "        \n",
    "        if file_extension == \".png\":\n",
    "            mime_type = \"image/png\"\n",
    "        elif file_extension in [\".jpg\", \".jpeg\"]:\n",
    "            mime_type = \"image/jpeg\"\n",
    "        elif file_extension == \".gif\":\n",
    "            mime_type = \"image/gif\"\n",
    "        elif file_extension == \".bmp\":\n",
    "            mime_type = \"image/bmp\"\n",
    "        elif file_extension == \".tiff\" or file_extension == \".tif\":\n",
    "            mime_type = \"image/tiff\"\n",
    "            \n",
    "        with open(image_path, \"rb\") as image_file:\n",
    "            encoded_string = base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
    "            return f\"data:{mime_type};base64,{encoded_string}\"\n",
    "    except Exception as e:\n",
    "        print(f\"Error encoding image {image_path}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4066 images in the data folder.\n"
     ]
    }
   ],
   "source": [
    "def get_image_paths(folder_path):\n",
    "    \"\"\"Get paths of all image files in the folder.\"\"\"\n",
    "    image_extensions = ['.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.gif']\n",
    "    image_paths = []\n",
    "    \n",
    "    for filename in os.listdir(folder_path):\n",
    "        if any(filename.lower().endswith(ext) for ext in image_extensions):\n",
    "            image_paths.append(os.path.join(folder_path, filename))\n",
    "    \n",
    "    return image_paths\n",
    "\n",
    "data_folder = \"1a0acabc-5140-425b-9eb8-f90e1721a6c3\"\n",
    "image_paths = get_image_paths(data_folder)\n",
    "#image_paths = image_paths[:10]\n",
    "print(f\"Found {len(image_paths)} images in the data folder.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4066/4066 [00:18<00:00, 221.48it/s]\n"
     ]
    }
   ],
   "source": [
    "# def create_batch_file_from_local(image_paths, output_file):\n",
    "#     with open(output_file, 'w') as file:\n",
    "#         for index, path in enumerate(tqdm(image_paths)):\n",
    "#             image_url = encode_image_data(path)\n",
    "#             if image_url:\n",
    "#                 entry = {\n",
    "#                     \"custom_id\": f\"{index}_{os.path.basename(path)}\",\n",
    "#                     \"body\": {\n",
    "#                         \"document\": {\n",
    "#                             \"type\": \"image_url\",\n",
    "#                             \"image_url\": image_url\n",
    "#                         },\n",
    "#                         \"include_image_base64\": True\n",
    "#                     }\n",
    "#                 }\n",
    "#                 file.write(json.dumps(entry) + '\\n')\n",
    "\n",
    "# batch_file = \"local_batch_file.jsonl\"\n",
    "# create_batch_file_from_local(image_paths, batch_file)\n",
    "\n",
    "\n",
    "def create_batch_files(image_paths, max_file_size_mb=512):\n",
    "    batch_files = []\n",
    "    batch_data = []\n",
    "    batch_size = 0  # Track current batch size\n",
    "    batch_index = 1\n",
    "    max_file_size_bytes = max_file_size_mb * 1024 * 1024\n",
    "    \n",
    "    for index, path in enumerate(tqdm(image_paths)):\n",
    "        image_data = encode_image_data(path)\n",
    "        if not image_data:\n",
    "            continue\n",
    "        \n",
    "        entry = {\n",
    "            \"custom_id\": f\"{index}_{os.path.basename(path)}\",\n",
    "            \"body\": {\n",
    "                \"document\": {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": image_data\n",
    "                },\n",
    "                \"include_image_base64\": True\n",
    "            }\n",
    "        }\n",
    "        entry_size = len(json.dumps(entry).encode('utf-8'))\n",
    "        \n",
    "        if batch_size + entry_size > max_file_size_bytes:\n",
    "            # Save the current batch and start a new one\n",
    "            batch_filename = f\"batch_file_{batch_index}.jsonl\"\n",
    "            with open(batch_filename, 'w') as file:\n",
    "                for item in batch_data:\n",
    "                    file.write(json.dumps(item) + '\\n')\n",
    "            batch_files.append(batch_filename)\n",
    "            \n",
    "            # Reset batch\n",
    "            batch_index += 1\n",
    "            batch_data = []\n",
    "            batch_size = 0\n",
    "        \n",
    "        batch_data.append(entry)\n",
    "        batch_size += entry_size\n",
    "    \n",
    "    # Save the last batch\n",
    "    if batch_data:\n",
    "        batch_filename = f\"batch_file_{batch_index}.jsonl\"\n",
    "        with open(batch_filename, 'w') as file:\n",
    "            for item in batch_data:\n",
    "                file.write(json.dumps(item) + '\\n')\n",
    "        batch_files.append(batch_filename)\n",
    "    \n",
    "    return batch_files\n",
    "\n",
    "batch_files = create_batch_files(image_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded batch_file_4.jsonl\n"
     ]
    }
   ],
   "source": [
    "# for batch_file in tqdm(batch_files):\n",
    "#     batch_data = client.files.upload(\n",
    "#         file={\n",
    "#             \"file_name\": batch_file,\n",
    "#             \"content\": open(batch_file, \"rb\")\n",
    "#         },\n",
    "#         purpose=\"batch\"\n",
    "#     )\n",
    "#     print(f\"Uploaded {batch_file}\")\n",
    "\n",
    "#     created_job = client.batch.jobs.create(\n",
    "#         input_files=[batch_data.id],\n",
    "#         model=ocr_model,\n",
    "#         endpoint=\"/v1/ocr\",\n",
    "#         metadata={\"job_type\": \"local_files_ocr2\"}\n",
    "#     )\n",
    "\n",
    "#     retrieved_job = client.batch.jobs.get(job_id=created_job.id)\n",
    "\n",
    "batch_data = client.files.upload(\n",
    "    file={\n",
    "        \"file_name\": batch_files[3],\n",
    "        \"content\": open(batch_files[1], \"rb\")\n",
    "    },\n",
    "    purpose=\"batch\"\n",
    ")\n",
    "print(f\"Uploaded {batch_files[3]}\")\n",
    "\n",
    "created_job = client.batch.jobs.create(\n",
    "    input_files=[batch_data.id],\n",
    "    model=ocr_model,\n",
    "    endpoint=\"/v1/ocr\",\n",
    "    metadata={\"job_type\": \"local_files_ocr2\"}\n",
    ")\n",
    "\n",
    "retrieved_job = client.batch.jobs.get(job_id=created_job.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: SUCCESS\n",
      "Total requests: 1153\n",
      "Failed requests: 0\n",
      "Successful requests: 1153\n",
      "Percent done: 100.0%\n"
     ]
    }
   ],
   "source": [
    "while retrieved_job.status in [\"QUEUED\", \"RUNNING\"]:\n",
    "    retrieved_job = client.batch.jobs.get(job_id=created_job.id)\n",
    "    \n",
    "    clear_output(wait=True)  # Clear the previous output\n",
    "    print(f\"Status: {retrieved_job.status}\")\n",
    "    print(f\"Total requests: {retrieved_job.total_requests}\")\n",
    "    print(f\"Failed requests: {retrieved_job.failed_requests}\")\n",
    "    print(f\"Successful requests: {retrieved_job.succeeded_requests}\")\n",
    "    print(\n",
    "        f\"Percent done: {round((retrieved_job.succeeded_requests + retrieved_job.failed_requests) / retrieved_job.total_requests, 4) * 100}%\"\n",
    "    )\n",
    "    time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_data = client.files.upload(\n",
    "#     file={\n",
    "#         \"file_name\": batch_file,\n",
    "#         \"content\": open(batch_file, \"rb\")\n",
    "#     },\n",
    "#     purpose=\"batch\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# created_job = client.batch.jobs.create(\n",
    "#     input_files=[batch_data.id],\n",
    "#     model=ocr_model,\n",
    "#     endpoint=\"/v1/ocr\",\n",
    "#     metadata={\"job_type\": \"local_files_ocr2\"}\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: SUCCESS\n",
      "Total requests: 10\n",
      "Failed requests: 0\n",
      "Successful requests: 10\n",
      "Percent done: 100.0%\n"
     ]
    }
   ],
   "source": [
    "# retrieved_job = client.batch.jobs.get(job_id=created_job.id)\n",
    "# while retrieved_job.status in [\"QUEUED\", \"RUNNING\"]:\n",
    "#     retrieved_job = client.batch.jobs.get(job_id=created_job.id)\n",
    "    \n",
    "#     clear_output(wait=True)  # Clear the previous output\n",
    "#     print(f\"Status: {retrieved_job.status}\")\n",
    "#     print(f\"Total requests: {retrieved_job.total_requests}\")\n",
    "#     print(f\"Failed requests: {retrieved_job.failed_requests}\")\n",
    "#     print(f\"Successful requests: {retrieved_job.succeeded_requests}\")\n",
    "#     print(\n",
    "#         f\"Percent done: {round((retrieved_job.succeeded_requests + retrieved_job.failed_requests) / retrieved_job.total_requests, 4) * 100}%\"\n",
    "#     )\n",
    "#     time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a6f1a923-5989-479f-a00e-57be9472479b'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieved_job.output_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200 OK]>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.files.download(file_id = 'a6f1a923-5989-479f-a00e-57be9472479b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = client.files.download(file_id = '8709905a-84a4-4758-bc7d-b18ade0d85b3')\n",
    "\n",
    "with open('file.jsonl', 'wb') as f:\n",
    "    f.write(output_file.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
