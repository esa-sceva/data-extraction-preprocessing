{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uy0fcqmnVVoW",
        "outputId": "c6a09eef-d7f6-47eb-a642-5bdce83ba1d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'GOT-OCR2.0'...\n",
            "remote: Enumerating objects: 371, done.\u001b[K\n",
            "remote: Counting objects: 100% (153/153), done.\u001b[K\n",
            "remote: Compressing objects: 100% (76/76), done.\u001b[K\n",
            "remote: Total 371 (delta 144), reused 77 (delta 77), pack-reused 218 (from 5)\u001b[K\n",
            "Receiving objects: 100% (371/371), 9.53 MiB | 10.86 MiB/s, done.\n",
            "Resolving deltas: 100% (188/188), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/Ucas-HaoranWei/GOT-OCR2.0.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/GOT-OCR2.0/GOT-OCR-2.0-master\n",
        "!pip install -e .\n",
        "!pip install ninja\n",
        "!pip install flash-attn --no-build-isolation\n",
        "%cd /content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OF-NOp-hVw0w",
        "outputId": "1a2ede8e-05d1-490b-cc12-e6d7054ab57a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/GOT-OCR2.0/GOT-OCR-2.0-master\n",
            "Obtaining file:///content/GOT-OCR2.0/GOT-OCR-2.0-master\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting markdown2[all] (from GOT==0.1.0)\n",
            "  Downloading markdown2-2.5.3-py3-none-any.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from GOT==0.1.0) (1.26.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from GOT==0.1.0) (2.32.3)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from GOT==0.1.0) (0.2.0)\n",
            "Requirement already satisfied: tokenizers>=0.15.2 in /usr/local/lib/python3.11/dist-packages (from GOT==0.1.0) (0.21.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from GOT==0.1.0) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from GOT==0.1.0) (0.21.0+cu124)\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.11/dist-packages (from GOT==0.1.0) (0.19.8)\n",
            "Collecting shortuuid (from GOT==0.1.0)\n",
            "  Downloading shortuuid-1.0.13-py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting httpx==0.24.0 (from GOT==0.1.0)\n",
            "  Downloading httpx-0.24.0-py3-none-any.whl.metadata (8.1 kB)\n",
            "Collecting deepspeed==0.12.3 (from GOT==0.1.0)\n",
            "  Downloading deepspeed-0.12.3.tar.gz (1.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting peft==0.4.0 (from GOT==0.1.0)\n",
            "  Downloading peft-0.4.0-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: albumentations in /usr/local/lib/python3.11/dist-packages (from GOT==0.1.0) (2.0.5)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (from GOT==0.1.0) (4.11.0.86)\n",
            "Collecting tiktoken==0.6.0 (from GOT==0.1.0)\n",
            "  Downloading tiktoken-0.6.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Collecting accelerate==0.28.0 (from GOT==0.1.0)\n",
            "  Downloading accelerate-0.28.0-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting transformers==4.37.2 (from GOT==0.1.0)\n",
            "  Downloading transformers-4.37.2-py3-none-any.whl.metadata (129 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.4/129.4 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting bitsandbytes==0.41.0 (from GOT==0.1.0)\n",
            "  Downloading bitsandbytes-0.41.0-py3-none-any.whl.metadata (9.8 kB)\n",
            "Collecting scikit-learn==1.2.2 (from GOT==0.1.0)\n",
            "  Downloading scikit_learn-1.2.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Collecting sentencepiece (from GOT==0.1.0)\n",
            "  Downloading sentencepiece-0.1.99-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
            "Collecting einops==0.6.1 (from GOT==0.1.0)\n",
            "  Downloading einops-0.6.1-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting einops-exts==0.0.4 (from GOT==0.1.0)\n",
            "  Downloading einops_exts-0.0.4-py3-none-any.whl.metadata (621 bytes)\n",
            "Collecting timm==0.6.13 (from GOT==0.1.0)\n",
            "  Downloading timm-0.6.13-py3-none-any.whl.metadata (38 kB)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from accelerate==0.28.0->GOT==0.1.0) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate==0.28.0->GOT==0.1.0) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate==0.28.0->GOT==0.1.0) (6.0.2)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.11/dist-packages (from accelerate==0.28.0->GOT==0.1.0) (0.28.1)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from accelerate==0.28.0->GOT==0.1.0) (0.5.3)\n",
            "Collecting hjson (from deepspeed==0.12.3->GOT==0.1.0)\n",
            "  Downloading hjson-3.1.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting ninja (from deepspeed==0.12.3->GOT==0.1.0)\n",
            "  Downloading ninja-1.11.1.3-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (5.3 kB)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from deepspeed==0.12.3->GOT==0.1.0) (9.0.0)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.11/dist-packages (from deepspeed==0.12.3->GOT==0.1.0) (2.10.6)\n",
            "Requirement already satisfied: pynvml in /usr/local/lib/python3.11/dist-packages (from deepspeed==0.12.3->GOT==0.1.0) (12.0.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from deepspeed==0.12.3->GOT==0.1.0) (4.67.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx==0.24.0->GOT==0.1.0) (2025.1.31)\n",
            "Collecting httpcore<0.18.0,>=0.15.0 (from httpx==0.24.0->GOT==0.1.0)\n",
            "  Downloading httpcore-0.17.3-py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx==0.24.0->GOT==0.1.0) (3.10)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from httpx==0.24.0->GOT==0.1.0) (1.3.1)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.2.2->GOT==0.1.0) (1.14.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.2.2->GOT==0.1.0) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.2.2->GOT==0.1.0) (3.5.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken==0.6.0->GOT==0.1.0) (2024.11.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers==4.37.2->GOT==0.1.0) (3.17.0)\n",
            "Collecting tokenizers>=0.15.2 (from GOT==0.1.0)\n",
            "  Downloading tokenizers-0.15.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->GOT==0.1.0) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->GOT==0.1.0) (2.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->GOT==0.1.0) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->GOT==0.1.0) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->GOT==0.1.0) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->GOT==0.1.0) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->GOT==0.1.0)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->GOT==0.1.0)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->GOT==0.1.0)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->GOT==0.1.0)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->GOT==0.1.0)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->GOT==0.1.0)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->GOT==0.1.0)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->GOT==0.1.0)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->GOT==0.1.0)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->GOT==0.1.0) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->GOT==0.1.0) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->GOT==0.1.0) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->GOT==0.1.0)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->GOT==0.1.0) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->GOT==0.1.0) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->GOT==0.1.0) (1.3.0)\n",
            "Requirement already satisfied: albucore==0.0.23 in /usr/local/lib/python3.11/dist-packages (from albumentations->GOT==0.1.0) (0.0.23)\n",
            "Requirement already satisfied: opencv-python-headless>=4.9.0.80 in /usr/local/lib/python3.11/dist-packages (from albumentations->GOT==0.1.0) (4.11.0.86)\n",
            "Requirement already satisfied: stringzilla>=3.10.4 in /usr/local/lib/python3.11/dist-packages (from albucore==0.0.23->albumentations->GOT==0.1.0) (3.12.3)\n",
            "Requirement already satisfied: simsimd>=5.9.2 in /usr/local/lib/python3.11/dist-packages (from albucore==0.0.23->albumentations->GOT==0.1.0) (6.2.1)\n",
            "Requirement already satisfied: pygments>=2.7.3 in /usr/local/lib/python3.11/dist-packages (from markdown2[all]->GOT==0.1.0) (2.18.0)\n",
            "Collecting wavedrom (from markdown2[all]->GOT==0.1.0)\n",
            "  Downloading wavedrom-2.0.3.post3.tar.gz (137 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.7/137.7 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting latex2mathml (from markdown2[all]->GOT==0.1.0)\n",
            "  Downloading latex2mathml-3.77.0-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision->GOT==0.1.0) (11.1.0)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.11/dist-packages (from wandb->GOT==0.1.0) (8.1.8)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from wandb->GOT==0.1.0) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb->GOT==0.1.0) (3.1.44)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb->GOT==0.1.0) (4.3.6)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from wandb->GOT==0.1.0) (4.25.6)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb->GOT==0.1.0) (2.22.0)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.11/dist-packages (from wandb->GOT==0.1.0) (1.3.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from wandb->GOT==0.1.0) (75.1.0)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from docker-pycreds>=0.4.0->wandb->GOT==0.1.0) (1.17.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb->GOT==0.1.0) (4.0.12)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore<0.18.0,>=0.15.0->httpx==0.24.0->GOT==0.1.0) (0.14.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from httpcore<0.18.0,>=0.15.0->httpx==0.24.0->GOT==0.1.0) (3.7.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->deepspeed==0.12.3->GOT==0.1.0) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic->deepspeed==0.12.3->GOT==0.1.0) (2.27.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->GOT==0.1.0) (3.0.2)\n",
            "Requirement already satisfied: nvidia-ml-py<13.0.0a0,>=12.0.0 in /usr/local/lib/python3.11/dist-packages (from pynvml->deepspeed==0.12.3->GOT==0.1.0) (12.570.86)\n",
            "Collecting svgwrite (from wavedrom->markdown2[all]->GOT==0.1.0)\n",
            "  Downloading svgwrite-1.4.3-py3-none-any.whl.metadata (8.8 kB)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb->GOT==0.1.0) (5.0.2)\n",
            "Downloading accelerate-0.28.0-py3-none-any.whl (290 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m290.1/290.1 kB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bitsandbytes-0.41.0-py3-none-any.whl (92.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.6/92.6 MB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading einops-0.6.1-py3-none-any.whl (42 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading einops_exts-0.0.4-py3-none-any.whl (3.9 kB)\n",
            "Downloading httpx-0.24.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.3/75.3 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading peft-0.4.0-py3-none-any.whl (72 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.9/72.9 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scikit_learn-1.2.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.6/9.6 MB\u001b[0m \u001b[31m76.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sentencepiece-0.1.99-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m50.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tiktoken-0.6.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m60.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading timm-0.6.13-py3-none-any.whl (549 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m549.1/549.1 kB\u001b[0m \u001b[31m35.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading transformers-4.37.2-py3-none-any.whl (8.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m73.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tokenizers-0.15.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m68.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m87.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m71.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m55.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m89.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading shortuuid-1.0.13-py3-none-any.whl (10 kB)\n",
            "Downloading httpcore-0.17.3-py3-none-any.whl (74 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.5/74.5 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading hjson-3.1.0-py3-none-any.whl (54 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.0/54.0 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading latex2mathml-3.77.0-py3-none-any.whl (73 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.7/73.7 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading markdown2-2.5.3-py3-none-any.whl (48 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.5/48.5 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ninja-1.11.1.3-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (422 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m422.9/422.9 kB\u001b[0m \u001b[31m37.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading svgwrite-1.4.3-py3-none-any.whl (67 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.1/67.1 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: GOT, deepspeed, wavedrom\n",
            "  Building editable for GOT (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for GOT: filename=got-0.1.0-0.editable-py3-none-any.whl size=3069 sha256=d842a86b2f4f385b58c88424510fb0b0b3e5b23604dbbbab6e5a46826ae01631\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-l51uhy9p/wheels/08/ae/0d/2d0ac6c1181fa71746fd81a265bc36ade516ff4de805b46167\n",
            "  Building wheel for deepspeed (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for deepspeed: filename=deepspeed-0.12.3-py3-none-any.whl size=1279163 sha256=6747bbf9c577c33559606d331bc02ded186c3dbcd81ff9e253f63e2430f5b1ea\n",
            "  Stored in directory: /root/.cache/pip/wheels/5d/a2/ba/e2880049c04875afc5d33ce35cbee5e2ffbcebadc57161cba0\n",
            "  Building wheel for wavedrom (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wavedrom: filename=wavedrom-2.0.3.post3-py2.py3-none-any.whl size=30082 sha256=d6af3de1edc4a1cf67ac17aff165d14ed5c721502467fbc7421629e8db5e8754\n",
            "  Stored in directory: /root/.cache/pip/wheels/23/cf/3b/4dcf6b22fa41c5ece715fa5f4e05afd683e7b0ce0f2fcc7bb6\n",
            "Successfully built GOT deepspeed wavedrom\n",
            "Installing collected packages: sentencepiece, hjson, bitsandbytes, svgwrite, shortuuid, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, ninja, markdown2, latex2mathml, einops, wavedrom, tiktoken, scikit-learn, nvidia-cusparse-cu12, nvidia-cudnn-cu12, httpcore, einops-exts, tokenizers, nvidia-cusolver-cu12, httpx, transformers, deepspeed, accelerate, timm, peft, GOT\n",
            "  Attempting uninstall: sentencepiece\n",
            "    Found existing installation: sentencepiece 0.2.0\n",
            "    Uninstalling sentencepiece-0.2.0:\n",
            "      Successfully uninstalled sentencepiece-0.2.0\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: einops\n",
            "    Found existing installation: einops 0.8.1\n",
            "    Uninstalling einops-0.8.1:\n",
            "      Successfully uninstalled einops-0.8.1\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.6.1\n",
            "    Uninstalling scikit-learn-1.6.1:\n",
            "      Successfully uninstalled scikit-learn-1.6.1\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: httpcore\n",
            "    Found existing installation: httpcore 1.0.7\n",
            "    Uninstalling httpcore-1.0.7:\n",
            "      Successfully uninstalled httpcore-1.0.7\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.21.0\n",
            "    Uninstalling tokenizers-0.21.0:\n",
            "      Successfully uninstalled tokenizers-0.21.0\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "  Attempting uninstall: httpx\n",
            "    Found existing installation: httpx 0.28.1\n",
            "    Uninstalling httpx-0.28.1:\n",
            "      Successfully uninstalled httpx-0.28.1\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.48.3\n",
            "    Uninstalling transformers-4.48.3:\n",
            "      Successfully uninstalled transformers-4.48.3\n",
            "  Attempting uninstall: accelerate\n",
            "    Found existing installation: accelerate 1.3.0\n",
            "    Uninstalling accelerate-1.3.0:\n",
            "      Successfully uninstalled accelerate-1.3.0\n",
            "  Attempting uninstall: timm\n",
            "    Found existing installation: timm 1.0.15\n",
            "    Uninstalling timm-1.0.15:\n",
            "      Successfully uninstalled timm-1.0.15\n",
            "  Attempting uninstall: peft\n",
            "    Found existing installation: peft 0.14.0\n",
            "    Uninstalling peft-0.14.0:\n",
            "      Successfully uninstalled peft-0.14.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "imbalanced-learn 0.13.0 requires scikit-learn<2,>=1.3.2, but you have scikit-learn 1.2.2 which is incompatible.\n",
            "mlxtend 0.23.4 requires scikit-learn>=1.3.1, but you have scikit-learn 1.2.2 which is incompatible.\n",
            "sentence-transformers 3.4.1 requires transformers<5.0.0,>=4.41.0, but you have transformers 4.37.2 which is incompatible.\n",
            "google-genai 1.4.0 requires httpx<1.0.0dev,>=0.28.1, but you have httpx 0.24.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed GOT-0.1.0 accelerate-0.28.0 bitsandbytes-0.41.0 deepspeed-0.12.3 einops-0.6.1 einops-exts-0.0.4 hjson-3.1.0 httpcore-0.17.3 httpx-0.24.0 latex2mathml-3.77.0 markdown2-2.5.3 ninja-1.11.1.3 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 peft-0.4.0 scikit-learn-1.2.2 sentencepiece-0.1.99 shortuuid-1.0.13 svgwrite-1.4.3 tiktoken-0.6.0 timm-0.6.13 tokenizers-0.15.2 transformers-4.37.2 wavedrom-2.0.3.post3\n",
            "Requirement already satisfied: ninja in /usr/local/lib/python3.11/dist-packages (1.11.1.3)\n",
            "Collecting flash-attn\n",
            "  Downloading flash_attn-2.7.4.post1.tar.gz (6.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m67.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from flash-attn) (2.6.0+cu124)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from flash-attn) (0.6.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->flash-attn) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->flash-attn) (3.0.2)\n",
            "Building wheels for collected packages: flash-attn\n",
            "  Building wheel for flash-attn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for flash-attn: filename=flash_attn-2.7.4.post1-cp311-cp311-linux_x86_64.whl size=187831595 sha256=58853b28a5a926cae14402bfd8d4d93a45ebf8f9e79533f37ab09d0d77a99c05\n",
            "  Stored in directory: /root/.cache/pip/wheels/3d/88/d8/284b89f56af7d5bf366b10d6b8e251ac8a7c7bf3f04203fb4f\n",
            "Successfully built flash-attn\n",
            "Installing collected packages: flash-attn\n",
            "Successfully installed flash-attn-2.7.4.post1\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gdown\n",
        "\n",
        "\n",
        "file_id = '1OQrXq_NB_QbJD9yPab6MSj0mcUD4DcrX'\n",
        "url = f'https://drive.google.com/uc?id={file_id}'\n",
        "output = 'GOT_weights.zip'\n",
        "\n",
        "gdown.download(url, output, quiet=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "6XK-_brWcm5H",
        "outputId": "0bc4ef77-ed8d-4cfa-8cc9-338051f36a9b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1OQrXq_NB_QbJD9yPab6MSj0mcUD4DcrX\n",
            "From (redirected): https://drive.google.com/uc?id=1OQrXq_NB_QbJD9yPab6MSj0mcUD4DcrX&confirm=t&uuid=37776eb1-6539-439f-ab86-eee6b7cbd3e6\n",
            "To: /content/GOT_weights.zip\n",
            "100%|██████████| 1.14G/1.14G [00:15<00:00, 71.1MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'GOT_weights.zip'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/GOT_weights.zip -d /content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VBhBSeadYzBI",
        "outputId": "02960f70-bd9e-4c47-da6a-f0ae63aa4836"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/GOT_weights.zip\n",
            "   creating: /content/GOT_weights/\n",
            "  inflating: /content/__MACOSX/._GOT_weights  \n",
            "  inflating: /content/GOT_weights/model.safetensors  \n",
            "  inflating: /content/__MACOSX/GOT_weights/._model.safetensors  \n",
            "  inflating: /content/GOT_weights/tokenizer_config.json  \n",
            "  inflating: /content/__MACOSX/GOT_weights/._tokenizer_config.json  \n",
            "  inflating: /content/GOT_weights/special_tokens_map.json  \n",
            "  inflating: /content/__MACOSX/GOT_weights/._special_tokens_map.json  \n",
            "  inflating: /content/GOT_weights/config.json  \n",
            "  inflating: /content/__MACOSX/GOT_weights/._config.json  \n",
            "  inflating: /content/GOT_weights/qwen.tiktoken  \n",
            "  inflating: /content/__MACOSX/GOT_weights/._qwen.tiktoken  \n",
            "  inflating: /content/GOT_weights/generation_config.json  \n",
            "  inflating: /content/__MACOSX/GOT_weights/._generation_config.json  \n",
            "  inflating: /content/GOT_weights/tokenization_qwen.py  \n",
            "  inflating: /content/__MACOSX/GOT_weights/._tokenization_qwen.py  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/GOT-OCR2.0/GOT-OCR-2.0-master/GOT/demo/run_ocr_2.0.py --model-name /content/GOT_weights/ --image-file /content/2.jpg --type ocr"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PPgcIOO6apNJ",
        "outputId": "d8ff8a39-d327-48f0-f7c3-7741cefe6aa8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-03-17 16:17:16.792744: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1742228236.815213    3355 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1742228236.821465    3355 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "<|im_start|>system\n",
            "You should follow the instructions carefully and explain your answers in detail.<|im_end|><|im_start|>user\n",
            "<img><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad><imgpad></img>\n",
            "OCR: <|im_end|><|im_start|>assistant\n",
            "\n",
            "Table 1: Comparisons of various RS synthetic datasets based on diversity, image capture details, asset \n",
            "origins, tasks, and the number of images. The diversity is categorized into City-Replica (datasets \n",
            "mimicking specific cities) and Style-Extended (covering a range of urban styles). Image capture \n",
            "attributes include GSD, resolution, and perspective (Nadir, Oblique). Asset origins are denoted as \n",
            "Manually-made (M), Game-origin (G), Procedurally-generated (P), and Real (R). Tasks cover Change \n",
            "Detection (CD), Building Segmentation (BS), Object Detection (OD), Disparity Estimation (DE), \n",
            "Height Estimation (HE), Land Cover (LC), and Building Change Detection (BCD). \n",
            "RS Synthetic Datasets \n",
            "Diversity \n",
            "Test \n",
            "# Images \n",
            "RST \n",
            "City-Replica \n",
            "Dispute \n",
            "Safal \n",
            "Safal \n",
            "Safal \n",
            "Safal \n",
            "Safal \n",
            "Safai \n",
            "Safai \n",
            "Safai \n",
            "Safai \n",
            "Safai \n",
            "Safal \n",
            "Safai \n",
            "Safai \n",
            "Safai \n",
            "Safal \n",
            "Safal \n",
            "Safai \n",
            "Safai \n",
            "Safal \n",
            "Safai \n",
            "Safal \n",
            "Safai \n",
            "Safai \n",
            "Safal \n",
            "Safal \n",
            "Safal \n",
            "Safai \n",
            "Safal \n",
            "Safai \n",
            "Safal \n",
            "Safal \n",
            "Safai \n",
            "Safal \n",
            "Safal \n",
            "Safal \n",
            "Safal \n",
            "Safa \n",
            "Safa \n",
            "Safa \n",
            "Safa \n",
            "Safa \n",
            "Safai \n",
            "Safai \n",
            "Safai \n",
            "Safai \n",
            "Safa \n",
            "Safai \n",
            "Safai \n",
            "Safai \n",
            "Safa \n",
            "Safa \n",
            "Safa \n",
            "Safa \n",
            "Safaa \n",
            "Safaa \n",
            "Safaa \n",
            "Safaa \n",
            "Safaa \n",
            "Safa \n",
            "Safaa \n",
            "Safaa \n",
            "Safaa \n",
            "Safa \n",
            "Safa \n",
            "Safaa \n",
            "Safaa \n",
            "Safa \n",
            "Safaa \n",
            "Safa \n",
            "Safaa \n",
            "Safaa \n",
            "Safa \n",
            "Safa \n",
            "Safa \n",
            "Safaa \n",
            "Safa \n",
            "Safaa \n",
            "Safa \n",
            "Safa \n",
            "Safaa \n",
            "Safa \n",
            "Safa \n",
            "Safa \n",
            "Safa \n",
            "Safae \n",
            "Safae \n",
            "Safae \n",
            "Safae \n",
            "Safae \n",
            "Safaa \n",
            "Safaa \n",
            "Safaa \n",
            "Safaa \n",
            "Safae \n",
            "Safaa \n",
            "Safaa \n",
            "Safaa \n",
            "Safa \n",
            "Safae \n",
            "Safaa \n",
            "Safaa \n",
            "Safaa \n",
            "Safae \n",
            "Safae \n",
            "Safaa \n",
            "Safaa \n",
            "Safae \n",
            "Safaa \n",
            "Safae \n",
            "Safaa \n",
            "Safaa \n",
            "Safae \n",
            "Safae \n",
            "Safae \n",
            "Safaa \n",
            "Safae \n",
            "Safaa \n",
            "Safae \n",
            "Safae \n",
            "Safaa \n",
            "Safae \n",
            "Safae \n",
            "Safae \n",
            "Safae \n",
            "Safa \n",
            "Safaa \n",
            "Safaa \n",
            "Safaa \n",
            "Safae \n",
            "Safa \n",
            "Safaa \n",
            "Safaa \n",
            "Safae \n",
            "Safaa \n",
            "Safa \n",
            "Safaa \n",
            "Safaa \n",
            "Safae \n",
            "Safae \n",
            "Safa \n",
            "Safaa \n",
            "Safae \n",
            "Safaa \n",
            "Safaa \n",
            "Safa \n",
            "Safaa \n",
            "Safae \n",
            "Safaa \n",
            "Safae \n",
            "Safa \n",
            "Safaa \n",
            "Safae \n",
            "Safae \n",
            "Safaa \n",
            "Safa \n",
            "Safaa \n",
            "Safae \n",
            "Safae \n",
            "Safae \n",
            "Safa \n",
            "Safae \n",
            "Safaa \n",
            "Safaa \n",
            "Safae \n",
            "Safa \n",
            "Safae \n",
            "Safaa \n",
            "Safae \n",
            "Safaa \n",
            "Safa \n",
            "Safae \n",
            "Safaa \n",
            "Safae \n",
            "Safae \n",
            "Safa \n",
            "Safae \n",
            "Safae \n",
            "Safaa \n",
            "Safaa \n",
            "Safa \n",
            "Safae \n",
            "Safae \n",
            "Safaa \n",
            "Safae \n",
            "Safa \n",
            "Safae \n",
            "Safae \n",
            "Safae \n",
            "Safaa \n",
            "Safa \n",
            "Safae \n",
            "Safae \n",
            "Safae \n",
            "Safa \n",
            "Safa \n",
            "Safaa \n",
            "Safaa \n",
            "Safae \n",
            "Safa \n",
            "Safa \n",
            "Safaa \n",
            "Safae \n",
            "Safaa \n",
            "Safa \n",
            "Safa \n",
            "Safaa \n",
            "Safae \n",
            "Safae \n",
            "Safa \n",
            "Safa \n",
            "Safae \n",
            "Safaa \n",
            "Safaa \n",
            "Safa \n",
            "Safa \n",
            "Safae \n",
            "Safaa \n",
            "Safae \n",
            "Safa \n",
            "Safa \n",
            "Safae \n",
            "Safae \n",
            "Safaa \n",
            "Safa \n",
            "Safa \n",
            "Safa \n",
            "Safae \n",
            "Safaa \n",
            "Safa \n",
            "Safaa \n",
            "Safa \n",
            "Safae \n",
            "Safaa \n",
            "Safa \n",
            "Safae \n",
            "Safa \n",
            "Safaa \n",
            "Safaa \n",
            "Safa \n",
            "Safae \n",
            "Safa \n",
            "Safa \n",
            "Safaa \n",
            "Safa \n",
            "Safae \n",
            "Safae \n",
            "Safa \n",
            "Safaa \n",
            "Safa \n",
            "Safaa \n",
            "Safae \n",
            "Safa \n",
            "Safaa \n",
            "Safa \n",
            "Safae \n",
            "Safa \n",
            "Safae \n",
            "Safaa \n",
            "Safa \n",
            "Safa \n",
            "Safae \n",
            "Safae \n",
            "Safa \n",
            "Safae \n",
            "Safa \n",
            "Safaa \n",
            "Safa \n",
            "Safa \n",
            "Safae \n",
            "Safa \n",
            "Safaa \n",
            "Safae \n",
            "Safa \n",
            "Safae \n",
            "Safa \n",
            "Safae \n",
            "Safae \n",
            "Safa \n",
            "Safa \n",
            "Safa \n",
            "Safaa \n",
            "Safae \n",
            "Safa \n",
            "Safa \n",
            "Safa \n",
            "Safae \n",
            "Safa \n",
            "Safae \n",
            "Safa \n",
            "Safa \n",
            "Safae \n",
            "Safa \n",
            "Safa \n",
            "Safa \n",
            "Safa \n",
            "Safao \n",
            "Safaa \n",
            "Safaa \n",
            "Safaa \n",
            "Safaa \n",
            "Safao \n",
            "Safaa \n",
            "Safaa \n",
            "Safaa \n",
            "Safae \n",
            "Safao \n",
            "Safaa \n",
            "Safaa \n",
            "Safaa \n",
            "Safa \n",
            "Safao \n",
            "Safaa \n",
            "Safaa \n",
            "Safae \n",
            "Safaa \n",
            "Safao \n",
            "Safaa \n",
            "Safaa \n",
            "Safae \n",
            "Safae \n",
            "Safao \n",
            "Safaa \n",
            "Safaa \n",
            "Safae \n",
            "Safa \n",
            "Safao \n",
            "Safaa \n",
            "Safaa \n",
            "Safa \n",
            "Safaa \n",
            "Safao \n",
            "Safaa \n",
            "Safaa \n",
            "Safa \n",
            "Safae \n",
            "Safao \n",
            "Safaa \n",
            "Safaa \n",
            "Safa \n",
            "Safa \n",
            "Safao \n",
            "Safaa \n",
            "Safae \n",
            "Safaa \n",
            "Safaa \n",
            "Safao \n",
            "Safaa \n",
            "Safae \n",
            "Safaa \n",
            "Safae \n",
            "Safao \n",
            "Safaa \n",
            "Safae \n",
            "Safaa \n",
            "Safa \n",
            "Safao \n",
            "Safaa \n",
            "Safae \n",
            "Safae \n",
            "Safaa \n",
            "Safao \n",
            "Safaa \n",
            "Safae \n",
            "Safae \n",
            "Safae \n",
            "Safao \n",
            "Safaa \n",
            "Safae \n",
            "Safae \n",
            "Safa \n",
            "Safao \n",
            "Safaa \n",
            "Safae \n",
            "Safa \n",
            "Safaa \n",
            "Safao \n",
            "Safaa \n",
            "Safae \n",
            "Safa \n",
            "Safae \n",
            "Safao \n",
            "Safaa \n",
            "Safae \n",
            "Safa \n",
            "Safa \n",
            "Safao \n",
            "Safaa \n",
            "Safa \n",
            "Safaa \n",
            "Safaa \n",
            "Safao \n",
            "Safaa \n",
            "Safa \n",
            "Safaa \n",
            "Safae \n",
            "Safao \n",
            "Safaa \n",
            "Safa \n",
            "Safaa \n",
            "Safa \n",
            "Safao \n",
            "Safaa \n",
            "Safa \n",
            "Safae \n",
            "Safaa \n",
            "Safao \n",
            "Safaa \n",
            "Safa \n",
            "Safae \n",
            "Safae \n",
            "Safao \n",
            "Safaa \n",
            "Safa \n",
            "Safae \n",
            "Safa \n",
            "Safao \n",
            "Safaa \n",
            "Safa \n",
            "Safa \n",
            "Safaa \n",
            "Safao \n",
            "Safaa \n",
            "Safa \n",
            "Safa \n",
            "Safae \n",
            "Safao \n",
            "Safaa \n",
            "Safa \n",
            "Safa \n",
            "Safa \n",
            "Safao \n",
            "Safa \n",
            "Safaa \n",
            "Safaa \n",
            "Safaa \n",
            "Safao \n",
            "Safa \n",
            "Safaa \n",
            "Safaa \n",
            "Safa \n",
            "Safao \n",
            "Safa \n",
            "Safaa \n",
            "Safa \n",
            "Safaa \n",
            "Safao \n",
            "Safa \n",
            "Safaa \n",
            "Safa \n",
            "Safae \n",
            "Safao \n",
            "Safa \n",
            "Safaa \n",
            "Safaa \n",
            "Safae \n",
            "Safao \n",
            "Safa \n",
            "Safaa \n",
            "Safa \n",
            "Safa \n",
            "Safao \n",
            "Safa \n",
            "Safae \n",
            "Safaa \n",
            "Safaa \n",
            "Safao \n",
            "Safa \n",
            "Safae \n",
            "Safaa \n",
            "Safa \n",
            "Safao \n",
            "Safa \n",
            "Safae \n",
            "Safae \n",
            "Safaa \n",
            "Safao \n",
            "Safa \n",
            "Safaa \n",
            "Safae \n",
            "Safaa \n",
            "Safao \n",
            "Safa \n",
            "Safae \n",
            "Safae \n",
            "Safae \n",
            "Safao \n",
            "Safa \n",
            "Safaa \n",
            "Safae \n",
            "Safae \n",
            "Safao \n",
            "Safae \n",
            "Safaa \n",
            "Safaa \n",
            "Safaa \n",
            "Safao \n",
            "Safae \n",
            "Safaa \n",
            "Safaa \n",
            "Safae \n",
            "Safao \n",
            "Safae \n",
            "Safaa \n",
            "Safae \n",
            "Safaa \n",
            "Safao \n",
            "Safae \n",
            "Safaa \n",
            "Safae \n",
            "Safae \n",
            "Safao \n",
            "Safa \n",
            "Safae \n",
            "Safaa \n",
            "Safae \n",
            "Safao \n",
            "Safae \n",
            "Safae \n",
            "Safaa \n",
            "Safaa \n",
            "Safao \n",
            "Safae \n",
            "Safae \n",
            "Safaa \n",
            "Safae \n",
            "Safao \n",
            "Safa \n",
            "Safae \n",
            "Safae \n",
            "Safao \n",
            "Safae \n",
            "Safae \n",
            "Safae \n",
            "Safaa \n",
            "Safao \n",
            "Safae \n",
            "Safae \n",
            "Safae \n",
            "Safae \n",
            "Safao \n",
            "Safae \n",
            "Safao \n",
            "Safaa \n",
            "Safaa \n",
            "Safao \n",
            "Safaa \n",
            "Safao \n",
            "Safaa \n",
            "Safaa \n",
            "Safao \n",
            "Safae \n",
            "Safao \n",
            "Safaa \n",
            "Safae \n",
            "Safao \n",
            "Safaa \n",
            "Safao \n",
            "Safaa \n",
            "Safae \n",
            "Safao \n",
            "Safae \n",
            "Safao \n",
            "Safae \n",
            "Safaa \n",
            "Safao \n",
            "Safaa \n",
            "Safao \n",
            "Safae \n",
            "Safaa \n",
            "Safao \n",
            "Safae \n",
            "Safao \n",
            "Safae \n",
            "Safae \n",
            "Safao \n",
            "Safaa \n",
            "Safao \n",
            "Safae \n",
            "Safae \n",
            "Safao \n",
            "Safae \n",
            "Safa \n",
            "Safaa \n",
            "Safaa \n",
            "Safao \n",
            "Safae \n",
            "Safa \n",
            "Safaa \n",
            "Safae \n",
            "Safao \n",
            "Safae \n",
            "Safa \n",
            "Safae \n",
            "Safaa \n",
            "Safao \n",
            "Safae \n",
            "Safa \n",
            "Safae \n",
            "Safae \n",
            "Safao \n",
            "Safa \n",
            "Safao \n",
            "Safaa \n",
            "Safaa \n",
            "Safao \n",
            "Safa \n",
            "Safao \n",
            "Safaa \n",
            "Safao \n",
            "Safaa \n",
            "Safao \n",
            "Safa \n",
            "Safaa \n",
            "Safao \n",
            "Safaa \n",
            "Safao \n",
            "Safao \n",
            "Safaa \n",
            "Safaa \n",
            "Safaa \n",
            "Safao \n",
            "Safao \n",
            "Safaa \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AFNABwBV3iCD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}